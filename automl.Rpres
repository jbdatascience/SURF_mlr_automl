---
output:
  ioslides_presentation:
    
---

<style>

.reveal .slides section h1  {
    font-size: 120pt;
}

.reveal .slides section h3  {
    font-size: 60pt;
}

.reveal .slides section p  {
    font-size: 40pt;
}

.reveal .slides section .slideContent p  {
    font-size: 1em;
}

.reveal .slides section .slideContent {
    font-size: 15pt;
}

</style>

```{r, echo=F}
options(width = 200)
```

Automatic Machine Learning
========================================================
width: 1920
height: 1024
author: Jose Magana
date: 2 Nov 2017
autosize: true

License
=======================================================
Copyright 2017 Jose A. Magana Mesa

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

What is the purpose
========================================================

- Support Data Scientists, not replace them. 
  - Many tools advertise as Automating Data Science but they don't!!
- Free time dedicated to routine low value tasks ( 2 out of [the 4D's](https://www.forbes.com/sites/bernardmarr/2017/10/16/the-4-ds-of-robotization-dull-dirty-dangerous-and-dear): Dull and Dirty)
- Allow quick iteration given different problem frames 

![](automl-figure/computers-algorithm-big_data-data_science-data_analytics-job_loss-jcen1731_low.jpg)
  
What can then Automatic Machine Learning do
========================================================

- Exploratory data analysis
- Machine learning pipeline: 
 - Redundant features
 - Missing value imputation
- Model selection
- Hyperparameter tuning
- ? Model diagnose
- ? KPI extraction

One image is better than 1000 words
===============================================

![](automl-figure/tpot-ml-pipeline.png)

Source: [TPOT](http://rhiever.github.io/tpot/)

Existing solutions (Far from exhaustive)
========================================================

- Auto sklearn, winner of the ChaLearn AutoML challenge (Python)
- [TPOT](http://rhiever.github.io/tpot/) (Python)
- [Data Robot](https://www.datarobot.com/) (commercial)
- [Skytree](http://www.skytree.net) (commercial)
- [Automatic Statistician](https://www.automaticstatistician.com) (for Exploratory Data Analysis)

What about R
==================================================

- Caret
- MLR
- H2O (also for Python)

An H2O example
=================

H2O is designed for simplicity, the less parameters (14) the better, but not very extendable:

h2o.automl(x, y, training_frame, validation_frame = NULL,
leaderboard_frame = NULL, fold_column = NULL, weights_column = NULL,
max_runtime_secs = 3600, max_models = NULL, stopping_metric = c("AUTO",
"deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE", "AUC", "lift_top_group",
"misclassification", "mean_per_class_error"), stopping_tolerance = NULL,
stopping_rounds = 3, seed = NULL, project_name = NULL)

```{r, eval=FALSE}

library(h2o)

h2o.init()

# Import a sample binary outcome train/test set into H2O
train <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv")
test <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv")

# Identify predictors and response
y <- "response"
x <- setdiff(names(train), y)

# For binary classification, response should be a factor
train[,y] <- as.factor(train[,y])
test[,y] <- as.factor(test[,y])

aml <- h2o.automl(x = x, y = y,
                  training_frame = train,
                  leaderboard_frame = test,
                  max_runtime_secs = 100)  # was 30

# If you need to generate predictions on a test set, you can make predictions directly on the 
# `"H2OAutoML"` object, or on the leader model object directly
pred <- h2o.predict(aml@leader, test)

# View the AutoML Leaderboard
 aml@leaderboard
#                                             model_id      auc  logloss
# 1           StackedEnsemble_model_1494643945817_1709 0.780384 0.561501
# 2 GBM_grid__95ebce3d26cd9d3997a3149454984550_model_0 0.764791 0.664823
# 3 GBM_grid__95ebce3d26cd9d3997a3149454984550_model_2 0.758109 0.593887
# 4                          DRF_model_1494643945817_3 0.736786 0.614430
# 5                        XRT_model_1494643945817_461 0.735946 0.602142
..
# 9 GLM_grid__95ebce3d26cd9d3997a3149454984550_model_0 0.685216 0.635137

```

An H20 example (2)
========================================================

```{r, eval=FALSE}
# The leader model is stored here
aml@leader
# Model Details:
# ==============
# 
# H2OBinomialModel: stackedensemble
# Model ID:  StackedEnsemble_0_AutoML_20171019_000411 
# NULL
# 
# 
# H2OBinomialMetrics: stackedensemble
# ** Reported on training data. **
# 
# MSE:  0.110144
# RMSE:  0.3318794
# LogLoss:  0.3738966
# Mean Per-Class Error:  0.133218
# AUC:  0.9485615
# Gini:  0.8971229
# 
# Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
#           0    1    Error       Rate
# 0      2658  645 0.195277  =645/3303
# 1       264 3446 0.071159  =264/3710
# Totals 2922 4091 0.129616  =909/7013
# 
# Maximum Metrics: Maximum metrics at their respective thresholds
#                         metric threshold    value idx
# 1                       max f1  0.457365 0.883476 223
# 2                       max f2  0.339376 0.925794 270
# 3                 max f0point5  0.620646 0.891058 155
# 4                 max accuracy  0.468095 0.871097 219
# 5                max precision  0.943729 1.000000   0
# 6                   max recall  0.170628 1.000000 348
# 7              max specificity  0.943729 1.000000   0
# 8             max absolute_mcc  0.468095 0.743003 219
# 9   max min_per_class_accuracy  0.529326 0.865577 193
# 10 max mean_per_class_accuracy  0.506534 0.869358 203
# 
# Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`

```

I have not been able to compare with the Kaggle Leaderboard, because the metric used is not implemented in H20.

Source: (H20)[http://h2o-release.s3.amazonaws.com/h2o/master/3888/docs-website/h2o-docs/automl.html#code-examples]

What is NOT Automatic Machine Learning
========================================================

Automatic Machine Learning is NOT Automatic Data Science.

<b>To date</b>, there is no production level algorithm that can translate a business need expressed in natural language to an algorithm. There are solutions that <b>claim</b> can convert data to personalised stories around that data in natural language. An example is: <b>https://narrativescience.com</b>

  ![Data](narrativescience.PNG)
  
  Store 9 your sales of item 6 are far below other stores in your region. If you are able to up your sales by only 5 units a day, you will be able to increase your profits by $1,123.
